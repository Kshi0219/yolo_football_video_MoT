{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "rf = Roboflow(api_key=\"EQazb1etxBV71iH6TAIX\")\n",
    "project = rf.workspace('kshi2').project(\"chelsea_newcastle_test\")\n",
    "model = project.version(1312).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\project\\yolo_football_video_MoT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n"
     ]
    }
   ],
   "source": [
    "cd c:/project/yolo_football_video_MoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in chelsea_newcastle_test-1312 to yolov9:: 100%|██████████| 4537/4537 [00:04<00:00, 1001.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to chelsea_newcastle_test-1312 in yolov9:: 100%|██████████| 216/216 [00:00<00:00, 1148.69it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset=project.version(1312).download('yolov9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4='C:/project/yolo_football_video_MoT/data/chelsea_newcastle_test.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info=sv.VideoInfo.from_video_path(mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoInfo(width=1920, height=1080, fps=30, total_frames=356)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "InferenceModel.predict_video() got an unexpected keyword argument 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m job_id, signed_url, expire_time \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_video\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmp4\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch-video\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpoll_until_video_results(job_id)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[1;31mTypeError\u001b[0m: InferenceModel.predict_video() got an unexpected keyword argument 'save'"
     ]
    }
   ],
   "source": [
    "job_id, signed_url, expire_time = model.predict_video(\n",
    "    mp4,\n",
    "    fps=5,\n",
    "    prediction_type=\"batch-video\"\n",
    ")\n",
    "\n",
    "results = model.poll_until_video_results(job_id)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['frame_offset', 'time_offset', 'chelsea_newcastle_test'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17625429388135672"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['chelsea_newcastle_test'][58]['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\project\\\\yolo_football_video_MoT\\\\chelsea_newcastle_test-1312'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1385235016.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[35], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    yolo task=detect mode=train model=yolov9.pt data={dataset.location}/data.yaml epochs=100 imgsz=640\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "yolo task=detect mode=train model=yolov9.pt data={dataset.location}/data.yaml epochs=100 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov9e.pt to 'yolov9e.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 792k/112M [00:07<28:31, 68.2kB/s] "
     ]
    }
   ],
   "source": [
    "model=YOLO('yolov9e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 쓰기 객체 생성\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (640, 480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for video inference results for job f2bf7b3f-a4f7-482e-85ff-b96bd7a6bf05 every 60s\n",
      "(0s): Checking for inference results\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m     annotated_image \u001b[38;5;241m=\u001b[39m label_annotator\u001b[38;5;241m.\u001b[39mannotate(\n\u001b[0;32m     18\u001b[0m         scene\u001b[38;5;241m=\u001b[39mannotated_image, detections\u001b[38;5;241m=\u001b[39mdetections, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m annotated_image\n\u001b[1;32m---> 22\u001b[0m \u001b[43msv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmp4\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\envs\\yolo_env\\Lib\\site-packages\\supervision\\utils\\video.py:205\u001b[0m, in \u001b[0;36mprocess_video\u001b[1;34m(source_path, target_path, callback)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m VideoSink(target_path\u001b[38;5;241m=\u001b[39mtarget_path, video_info\u001b[38;5;241m=\u001b[39msource_video_info) \u001b[38;5;28;01mas\u001b[39;00m sink:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, frame \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m    203\u001b[0m         get_video_frames_generator(source_path\u001b[38;5;241m=\u001b[39msource_path)\n\u001b[0;32m    204\u001b[0m     ):\n\u001b[1;32m--> 205\u001b[0m         result_frame \u001b[38;5;241m=\u001b[39m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m         sink\u001b[38;5;241m.\u001b[39mwrite_frame(frame\u001b[38;5;241m=\u001b[39mresult_frame)\n",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m, in \u001b[0;36mcallback\u001b[1;34m(scene, index)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcallback\u001b[39m(scene: np\u001b[38;5;241m.\u001b[39mndarray, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m----> 2\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll_until_video_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m     detections \u001b[38;5;241m=\u001b[39m sv\u001b[38;5;241m.\u001b[39mDetections\u001b[38;5;241m.\u001b[39mfrom_ultralytics(results)\n\u001b[0;32m      5\u001b[0m     bounding_box_annotator \u001b[38;5;241m=\u001b[39m sv\u001b[38;5;241m.\u001b[39mBoundingBoxAnnotator()\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "def callback(scene: np.ndarray, index: int) -> np.ndarray:\n",
    "    results = model.poll_until_video_results(job_id)[index]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "    bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "    labels = [\n",
    "        results.names[class_id]\n",
    "        for class_id\n",
    "        in detections.class_id\n",
    "    ]\n",
    "\n",
    "    annotated_image = bounding_box_annotator.annotate(\n",
    "        scene=scene, detections=detections)\n",
    "\n",
    "    annotated_image = label_annotator.annotate(\n",
    "        scene=annotated_image, detections=detections, labels=labels)\n",
    "\n",
    "    return annotated_image\n",
    "\n",
    "sv.process_video(\n",
    "    source_path=mp4,\n",
    "    target_path=\"output.mp4\",\n",
    "    callback=callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4read=cv2.VideoCapture(mp4)\n",
    "cap,frame=mp4read.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1920, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hex 색상코드를 RGB색상코드로 변경\n",
    "def hex_to_rgb(hex_color):\n",
    "    hex_color = hex_color.lstrip('#')\n",
    "    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://detect.roboflow.com/chelsea_newcastle/1?api_key=7LaCX25FUT6blBXw40FE&name=YOUR_IMAGE.jpg&overlap=30&confidence=50&stroke=1&labels=false&format=json",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# 프레임에서 객체 감지\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# 결과를 프레임에 표시\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m prediction:\n",
      "File \u001b[1;32mc:\\python_envs\\yolo_env\\Lib\\site-packages\\roboflow\\models\\object_detection.py:241\u001b[0m, in \u001b[0;36mObjectDetectionModel.predict\u001b[1;34m(self, image_path, hosted, format, classes, overlap, confidence, stroke, labels)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# POST to the API\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     resp \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_url)\n\u001b[1;32m--> 241\u001b[0m \u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# Return a prediction group if JSON data\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\python_envs\\yolo_env\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m     )\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://detect.roboflow.com/chelsea_newcastle/1?api_key=7LaCX25FUT6blBXw40FE&name=YOUR_IMAGE.jpg&overlap=30&confidence=50&stroke=1&labels=false&format=json"
     ]
    }
   ],
   "source": [
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # 프레임에서 객체 감지\n",
    "        prediction = model.predict(frame, confidence=50)\n",
    "        \n",
    "        # 결과를 프레임에 표시\n",
    "        for result in prediction:\n",
    "            bottom_right = (round(result['x']-result['width']/2), round(result['y']-result['height']/2))\n",
    "            top_left = (round(result['x']+result['width']/2), round(result['y']+result['height']/2))\n",
    "            color = hex_to_rgb(version.colors[result['class']])\n",
    "            thickness = 2\n",
    "            cv2.rectangle(frame, bottom_right, top_left, color, thickness)\n",
    "            cv2.putText(frame, result['class'], (round(result['x']-result['width']/2), round(result['y']-result['height']/2-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color=color, thickness=3)\n",
    "        \n",
    "        # 결과 프레임을 파일로 저장\n",
    "        out.write(frame)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# 모든 작업이 완료되면 캡처와 쓰기 객체를 해제\n",
    "cap.release()\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
